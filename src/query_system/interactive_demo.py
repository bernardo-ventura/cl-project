"""
Interactive Demo: Interface interativa para testar o sistema de consultas
"""

import os
import sys
import time
from pathlib import Path

# Adiciona o diretÃ³rio src ao path para imports
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.append(str(project_root))

from src.query_system.kg_executor import create_kg_executor
from src.query_system.query_processor import create_query_processor
from src.query_system.response_formatter import create_response_formatter
from src.query_system.response_enhancer import create_response_enhancer


class InteractiveDemo:
    def __init__(self, kg_path=None):
        print("ğŸš€ Inicializando Sistema de Consultas ao Knowledge Graph...")
        print("=" * 60)
        
        try:
            print("ğŸ”§ Carregando KG Executor...")
            self.kg_executor = create_kg_executor(kg_path)
            
            print("ğŸ§  Carregando Query Processor...")
            self.query_processor = create_query_processor()
            
            print("ğŸ¨ Carregando Response Formatter...")
            self.response_formatter = create_response_formatter()
            
            print("ğŸ¤– Carregando Response Enhancer (LLM)...")
            self.response_enhancer = create_response_enhancer()
            
            stats = self.kg_executor.get_stats()
            print(f"âœ… Sistema carregado com sucesso!")
            print(f"ğŸ“Š Knowledge Graph: {stats.get('total_triples', 'N/A')} triplas")
            print("=" * 60)
            
        except Exception as e:
            print(f"âŒ Erro ao carregar sistema: {e}")
            raise
    
    def process_question(self, question, show_debug=False, use_natural_language=True):
        start_time = time.time()
        
        try:
            if show_debug:
                print(f"ğŸ” Processando pergunta: '{question}'")
            
            intent, sparql_query = self.query_processor.process_and_generate(question)
            
            if show_debug:
                print(f"ğŸ¯ Tipo identificado: {intent.query_type.value}")
                print(f"ğŸ·ï¸ Entidades: {intent.entities}")
                print(f"ğŸ“ SPARQL gerado ({len(sparql_query)} chars)")
            
            results = self.kg_executor.execute_sparql(sparql_query)
            
            if show_debug:
                print(f"ğŸ“Š Resultados SPARQL: {len(results)} registros")
            
            formatted_response = self.response_formatter.format_response(
                results=results,
                query_type=intent.query_type,
                original_question=question,
                entities=intent.entities
            )
            
            # Nova funcionalidade: Enhancement com LLM
            if use_natural_language:
                try:
                    enhanced_response = self.response_enhancer.enhance_response(
                        formatted_response=formatted_response,
                        original_question=question,
                        query_type=intent.query_type.value
                    )
                    
                    main_answer = enhanced_response.natural_answer
                    llm_time = enhanced_response.processing_time
                    
                    if show_debug:
                        print(f"ğŸ¤– LLM Enhancement: {llm_time:.2f}s")
                    
                except Exception as e:
                    if show_debug:
                        print(f"âš ï¸ LLM Enhancement falhou: {e}")
                    # Fallback: usar resposta estruturada
                    main_answer = formatted_response.answer
                    llm_time = 0
            else:
                main_answer = formatted_response.answer
                llm_time = 0
            
            elapsed_time = time.time() - start_time
            
            response_parts = [
                main_answer,
                "",
                f"ğŸ”— **Fonte**: Knowledge Graph ML/DL",
                f"â±ï¸ **Tempo**: {elapsed_time:.2f}s" + (f" (LLM: {llm_time:.2f}s)" if llm_time > 0 else ""),
                f"ğŸ“Š **Resultados**: {formatted_response.metadata.get('result_count', 0)}",
                f"ğŸ¯ **ConfianÃ§a**: {formatted_response.confidence:.1%}"
            ]
            
            if show_debug:
                response_parts.extend([
                    f"ğŸ”§ **Debug**: {intent.query_type.value}",
                    f"ğŸ“ **SPARQL**: {len(sparql_query)} caracteres"
                ])
                
                # Mostra dados estruturados tambÃ©m no debug
                if use_natural_language:
                    response_parts.extend([
                        "",
                        "ğŸ“Š **Dados Estruturados Originais**:",
                        formatted_response.answer
                    ])
            
            return "\n".join(response_parts)
            
        except Exception as e:
            error_time = time.time() - start_time
            return f"âŒ **Erro ao processar pergunta**: {str(e)}\nâ±ï¸ **Tempo**: {error_time:.2f}s"
    
    def run_interactive_session(self):
        print("\nğŸ® MODO INTERATIVO")
        print("Digite suas perguntas sobre Machine Learning e Deep Learning!")
        print("Comandos especiais:")
        print("  â€¢ 'help' - mostra exemplos de perguntas")
        print("  â€¢ 'debug on/off' - ativa/desativa modo debug")
        print("  â€¢ 'natural on/off' - liga/desliga respostas naturais (LLM)")
        print("  â€¢ 'stats' - estatÃ­sticas do Knowledge Graph") 
        print("  â€¢ 'quit' - sair")
        print("-" * 60)
        
        debug_mode = False
        natural_mode = True  # Default: usar LLM para respostas naturais
        print(f"ğŸ¤– Modo Natural Language: {'ATIVO' if natural_mode else 'INATIVO'}")
        print(f"ğŸ”§ Debug mode: {'ATIVO' if debug_mode else 'INATIVO'}")
        
        while True:
            try:
                question = input("\nğŸ¤” Sua pergunta: ").strip()
                
                if not question:
                    continue
                    
                elif question.lower() == 'quit':
                    print("ğŸ‘‹ AtÃ© logo!")
                    break
                    
                elif question.lower() == 'help':
                    self._show_help()
                    
                elif question.lower() == 'stats':
                    self._show_stats()
                    
                elif question.lower() == 'debug on':
                    debug_mode = True
                    print("ğŸ”§ Modo debug ATIVADO")
                    
                elif question.lower() == 'debug off':
                    debug_mode = False
                    print("ğŸ”§ Modo debug DESATIVADO")
                    
                elif question.lower() == 'natural on':
                    natural_mode = True
                    print("ğŸ¤– Modo Natural Language ATIVADO (usando LLM)")
                    
                elif question.lower() == 'natural off':
                    natural_mode = False
                    print("ğŸ“Š Modo Natural Language DESATIVADO (respostas estruturadas)")
                    
                else:
                    print("\nğŸ¤– **Resposta:**")
                    print("-" * 40)
                    
                    response = self.process_question(question, show_debug=debug_mode, use_natural_language=natural_mode)
                    print(response)
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ SessÃ£o interrompida. AtÃ© logo!")
                break
            except Exception as e:
                print(f"\nâŒ Erro inesperado: {e}")
    
    def run_demo_questions(self):
        demo_questions = [
            "O que Ã© gradient descent?",
            "Quais algoritmos usam backpropagation?",
            "Adam optimizer Ã© um tipo de que?", 
            "Quem criou Support Vector Machine?",
            "Liste todos os algoritmos",
            "Como neural network estÃ¡ relacionado com deep learning?",
            "Encontre conceitos similares a CNN",
            "O que Ã© overfitting?"
        ]
        
        print("\nğŸ¬ DEMONSTRAÃ‡ÃƒO - Perguntas Exemplo")
        print("=" * 50)
        
        for i, question in enumerate(demo_questions, 1):
            print(f"\nğŸ“ **Pergunta {i}**: {question}")
            print("-" * 30)
            
            response = self.process_question(question)
            print(response)
            
            input("\nâ Pressione Enter para continuar...")
    
    def _show_help(self):
        examples = [
            "ğŸ“‹ **Exemplos de perguntas que vocÃª pode fazer:**",
            "",
            "ğŸ” **DefiniÃ§Ãµes:**",
            "   â€¢ O que Ã© gradient descent?",
            "   â€¢ Defina backpropagation",
            "   â€¢ Explique neural network",
            "",
            "ğŸ”§ **Uso e implementaÃ§Ã£o:**", 
            "   â€¢ Quais algoritmos usam gradient descent?",
            "   â€¢ O que implementa backpropagation?",
            "   â€¢ Algoritmos que usam CNN",
            "",
            "ğŸ·ï¸ **Hierarquia e tipos:**",
            "   â€¢ Adam optimizer Ã© um tipo de que?",
            "   â€¢ CNN Ã© uma subclasse de que?",
            "",
            "ğŸ‘¤ **Criadores e autores:**",
            "   â€¢ Quem criou Support Vector Machine?",
            "   â€¢ Quem desenvolveu LSTM?",
            "",
            "ğŸ“Š **Listagens:**",
            "   â€¢ Liste todos os algoritmos",
            "   â€¢ Quais sÃ£o as mÃ©tricas?",
            "   â€¢ Mostre todos os conceitos",
            "",
            "ğŸ”— **RelaÃ§Ãµes:**",
            "   â€¢ Como CNN estÃ¡ relacionado com deep learning?",
            "   â€¢ RelaÃ§Ã£o entre RNN e LSTM",
            "",
            "ğŸ” **Similaridade:**",
            "   â€¢ Encontre conceitos similares a CNN",
            "   â€¢ Algoritmos parecidos com SVM"
        ]
        
        print("\n" + "\n".join(examples))
    
    def _show_stats(self):
        try:
            stats = self.kg_executor.get_stats()
            
            print("\nğŸ“Š **EstatÃ­sticas do Knowledge Graph:**")
            print("-" * 35)
            print(f"ğŸ•¸ï¸ Total de triplas: {stats.get('total_triples', 'N/A'):,}")
            print(f"ğŸ·ï¸ Total de entidades: {stats.get('total_entities', 'N/A'):,}")
            print(f"ğŸ”— Total de relaÃ§Ãµes: {stats.get('total_relations', 'N/A'):,}")
            
        except Exception as e:
            print(f"âŒ Erro ao obter estatÃ­sticas: {e}")


def main():
    print("ğŸ§  SISTEMA DE CONSULTAS - KNOWLEDGE GRAPH ML/DL")
    print("=" * 60)
    
    try:
        demo = InteractiveDemo()
        
        print("\nEscolha uma opÃ§Ã£o:")
        print("1. Modo Interativo (vocÃª faz as perguntas)")
        print("2. DemonstraÃ§Ã£o (perguntas exemplo)")
        print("3. Sair")
        
        while True:
            choice = input("\nğŸ‘‰ Sua escolha (1/2/3): ").strip()
            
            if choice == '1':
                demo.run_interactive_session()
                break
            elif choice == '2':
                demo.run_demo_questions()
                break
            elif choice == '3':
                print("ğŸ‘‹ AtÃ© logo!")
                break
            else:
                print("âŒ OpÃ§Ã£o invÃ¡lida. Digite 1, 2 ou 3.")
    
    except Exception as e:
        print(f"âŒ Erro fatal: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)