"""
Demo Interativo do Sistema RAG
Interface CLI similar ao sistema KG para consultas em tempo real
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional

# Adicionar diret√≥rio do projeto ao path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.rag.rag_pipeline import create_rag_pipeline, RAGConfig


class RAGInteractiveDemo:
    """Interface interativa para o sistema RAG."""
    
    def __init__(self):
        """Inicializa a demo."""
        self.pipeline = None
        self.config = RAGConfig(
            top_k=5,
            response_style="comprehensive",
            debug_mode=False,
            save_history=True,
            include_sources=True,
            citation_style="bracket"
        )
        self.is_initialized = False
        self.stats = {
            'queries_processed': 0,
            'total_time': 0.0,
            'avg_confidence': 0.0
        }
    
    def initialize(self):
        """Inicializa o pipeline RAG."""
        if self.is_initialized:
            return
        
        print("üöÄ Inicializando sistema RAG...")
        print("‚è≥ Carregando componentes (isso pode demorar na primeira vez)...")
        
        start_time = time.time()
        self.pipeline = create_rag_pipeline(self.config)
        self.pipeline.initialize()
        init_time = time.time() - start_time
        
        self.is_initialized = True
        print(f"‚úÖ Sistema RAG inicializado em {init_time:.1f}s")
        print()
    
    def print_header(self):
        """Imprime cabe√ßalho da aplica√ß√£o."""
        print("ü§ñ " + "=" * 70)
        print("ü§ñ SISTEMA RAG - MACHINE LEARNING & DEEP LEARNING")
        print("ü§ñ Recupera√ß√£o e Gera√ß√£o Aumentada por Documentos")
        print("ü§ñ " + "=" * 70)
        print()
        print("üìö Base de conhecimento: 3,219 chunks de 8 livros de ML/DL")
        print("üîç Vector Store: FAISS com embeddings all-MiniLM-L6-v2") 
        print("ü§ñ LLM: Ollama (llama3.2:3b)")
        print()
    
    def print_help(self):
        """Imprime ajuda dos comandos."""
        print("üìã COMANDOS DISPON√çVEIS:")
        print("  help          - Mostra esta ajuda")
        print("  stats         - Estat√≠sticas do sistema")
        print("  config        - Mostra/altera configura√ß√µes")
        print("  debug on/off  - Liga/desliga modo debug")
        print("  style <style> - Altera estilo (comprehensive/concise/technical)")
        print("  topk <num>    - Define n√∫mero de documentos (1-10)")
        print("  history       - Mostra hist√≥rico de consultas")
        print("  clear         - Limpa hist√≥rico")
        print("  demo          - Executa demonstra√ß√£o autom√°tica")
        print("  quit/exit     - Sair do sistema")
        print()
        print("üí° Exemplos de consultas:")
        print("  ‚Ä¢ What is machine learning?")
        print("  ‚Ä¢ How does gradient descent work?")
        print("  ‚Ä¢ Explain neural networks and backpropagation")
        print("  ‚Ä¢ What is the difference between supervised and unsupervised learning?")
        print("  ‚Ä¢ How do convolutional neural networks work?")
        print()
    
    def print_stats(self):
        """Imprime estat√≠sticas do sistema."""
        if not self.is_initialized:
            print("‚ö†Ô∏è Sistema n√£o inicializado")
            return
        
        system_stats = self.pipeline.get_statistics()
        
        print("üìä ESTAT√çSTICAS DO SISTEMA RAG:")
        print(f"   Status: {'‚úÖ Inicializado' if system_stats['is_initialized'] else '‚ùå N√£o inicializado'}")
        print()
        
        # Stats do retriever
        if 'retriever' in system_stats:
            ret_stats = system_stats['retriever']
            print(f"üîç RETRIEVER:")
            print(f"   Documentos indexados: {ret_stats.get('vector_store', {}).get('total_documents', 'N/A')}")
            print(f"   Dimens√£o embeddings: {ret_stats.get('vector_store', {}).get('embedding_dimension', 'N/A')}")
            print(f"   Tipo de √≠ndice: {ret_stats.get('vector_store', {}).get('index_type', 'N/A')}")
            print()
        
        # Stats do generator
        if 'generator' in system_stats:
            gen_stats = system_stats['generator']
            print(f"ü§ñ GENERATOR:")
            print(f"   Ollama dispon√≠vel: {'‚úÖ' if gen_stats.get('ollama_available', False) else '‚ùå'}")
            print(f"   Modelo: {gen_stats.get('config', {}).get('model_name', 'N/A')}")
            print(f"   Temperatura: {gen_stats.get('config', {}).get('temperature', 'N/A')}")
            print()
        
        # Stats da sess√£o
        print(f"üìà SESS√ÉO ATUAL:")
        print(f"   Consultas processadas: {self.stats['queries_processed']}")
        if self.stats['queries_processed'] > 0:
            print(f"   Tempo m√©dio: {self.stats['total_time']/self.stats['queries_processed']:.2f}s")
            print(f"   Confian√ßa m√©dia: {self.stats['avg_confidence']/self.stats['queries_processed']:.2f}")
        print()
    
    def print_config(self):
        """Imprime configura√ß√µes atuais."""
        print("‚öôÔ∏è CONFIGURA√á√ïES ATUAIS:")
        print(f"   Top-K documentos: {self.config.top_k}")
        print(f"   Estilo de resposta: {self.config.response_style}")
        print(f"   Threshold similaridade: {self.config.similarity_threshold}")
        print(f"   Modo debug: {'‚úÖ' if self.config.debug_mode else '‚ùå'}")
        print(f"   Re-ranking: {'‚úÖ' if self.config.enable_reranking else '‚ùå'}")
        print(f"   Diversidade de livros: {'‚úÖ' if self.config.book_diversity else '‚ùå'}")
        print(f"   Incluir fontes: {'‚úÖ' if self.config.include_sources else '‚ùå'}")
        print(f"   Temperatura LLM: {self.config.temperature}")
        print()
    
    def run_demo(self):
        """Executa demonstra√ß√£o autom√°tica."""
        demo_queries = [
            "What is machine learning?",
            "How does gradient descent work?",
            "Explain overfitting and regularization",
            "What are support vector machines?",
            "How do neural networks learn?"
        ]
        
        print("üé™ DEMONSTRA√á√ÉO AUTOM√ÅTICA")
        print(f"Executando {len(demo_queries)} consultas de exemplo...")
        print()
        
        for i, query in enumerate(demo_queries, 1):
            print(f"üîé Demo {i}/{len(demo_queries)}: '{query}'")
            print("-" * 60)
            
            response = self.pipeline.query(query)
            
            print(f"‚è±Ô∏è  Tempo: {response.total_time:.2f}s")
            print(f"üìä Confian√ßa: {response.confidence_score:.2f}")
            print(f"üìÑ Documentos: {response.documents_used}")
            print()
            print("üí¨ RESPOSTA:")
            print(response.answer[:300] + "..." if len(response.answer) > 300 else response.answer)
            print()
            
            if response.sources:
                print(f"üìö Fontes: {len(response.sources)} livros referenciados")
            print()
        
        print("üéâ Demonstra√ß√£o conclu√≠da!")
        print()
    
    def process_command(self, user_input: str) -> bool:
        """
        Processa comandos especiais.
        
        Returns:
            True se foi um comando especial, False se √© consulta normal
        """
        command = user_input.lower().strip()
        
        if command in ['help', 'ajuda']:
            self.print_help()
            return True
        
        elif command == 'stats':
            self.print_stats()
            return True
        
        elif command == 'config':
            self.print_config()
            return True
        
        elif command.startswith('debug '):
            mode = command.split()[1]
            if mode == 'on':
                self.config.debug_mode = True
                print("üîç Modo debug ATIVADO")
            elif mode == 'off':
                self.config.debug_mode = False
                print("üîç Modo debug DESATIVADO")
            else:
                print("‚ö†Ô∏è Use: debug on/off")
            return True
        
        elif command.startswith('style '):
            style = command.split()[1]
            if style in ['comprehensive', 'concise', 'technical']:
                self.config.response_style = style
                print(f"üìù Estilo alterado para: {style}")
                if self.is_initialized:
                    print("‚ÑπÔ∏è Reinicializa√ß√£o necess√°ria para aplicar mudan√ßa")
            else:
                print("‚ö†Ô∏è Estilos dispon√≠veis: comprehensive, concise, technical")
            return True
        
        elif command.startswith('topk '):
            try:
                k = int(command.split()[1])
                if 1 <= k <= 10:
                    self.config.top_k = k
                    print(f"üìä Top-K alterado para: {k}")
                    if self.is_initialized:
                        print("‚ÑπÔ∏è Reinicializa√ß√£o necess√°ria para aplicar mudan√ßa")
                else:
                    print("‚ö†Ô∏è Top-K deve estar entre 1 e 10")
            except ValueError:
                print("‚ö†Ô∏è N√∫mero inv√°lido")
            return True
        
        elif command == 'history':
            if self.pipeline and hasattr(self.pipeline, 'query_history'):
                history = self.pipeline.query_history
                if history:
                    print(f"üìã HIST√ìRICO ({len(history)} consultas):")
                    for entry in history[-5:]:  # √öltimas 5
                        query = entry.get('query', 'N/A')
                        summary = entry.get('response_summary', {})
                        conf = summary.get('confidence', 0)
                        time_val = summary.get('total_time', 0)
                        print(f"   ‚Ä¢ {query[:50]}... (conf: {conf:.2f}, {time_val:.1f}s)")
                else:
                    print("üì≠ Hist√≥rico vazio")
            print()
            return True
        
        elif command == 'clear':
            if self.pipeline:
                self.pipeline.clear_history()
                self.stats = {'queries_processed': 0, 'total_time': 0.0, 'avg_confidence': 0.0}
            print("üóëÔ∏è Hist√≥rico limpo")
            return True
        
        elif command == 'demo':
            if not self.is_initialized:
                self.initialize()
            self.run_demo()
            return True
        
        elif command in ['quit', 'exit', 'sair']:
            return 'quit'
        
        return False
    
    def process_query(self, query: str):
        """Processa uma consulta normal."""
        if not self.is_initialized:
            self.initialize()
        
        print(f"üîç Processando: '{query}'")
        print()
        
        start_time = time.time()
        response = self.pipeline.query(query)
        
        # Atualizar stats
        self.stats['queries_processed'] += 1
        self.stats['total_time'] += response.total_time
        self.stats['avg_confidence'] += response.confidence_score
        
        # Mostrar resposta
        print("üí¨ RESPOSTA:")
        print("=" * 60)
        print(response.answer)
        print("=" * 60)
        print()
        
        # Mostrar m√©tricas
        print(f"‚è±Ô∏è  Tempo: {response.total_time:.2f}s")
        print(f"   Recupera√ß√£o: {response.retrieval_time:.3f}s")
        print(f"   Gera√ß√£o: {response.generation_time:.2f}s")
        print(f"üìä Confian√ßa: {response.confidence_score:.2f}")
        print(f"üìÑ Documentos: {response.documents_used}/{response.documents_found}")
        print(f"ü§ñ Modelo: {response.model_used}")
        
        # Mostrar fontes
        if response.sources:
            print(f"\nüìö FONTES ({len(response.sources)}):")
            for i, source in enumerate(response.sources, 1):
                print(f"   {i}. {source}")
        
        # Debug info
        if self.config.debug_mode and response.retrieval_debug:
            print(f"\nüîç DEBUG INFO:")
            print(f"   Query analysis: {response.retrieval_debug.get('query_analysis', {})}")
            print(f"   Context length: {response.generation_debug.get('context_length', 'N/A')} chars")
        
        print()
    
    def run(self):
        """Executa a interface interativa."""
        self.print_header()
        
        print("üí° Digite 'help' para ver comandos dispon√≠veis")
        print("üí° Digite 'demo' para ver demonstra√ß√£o autom√°tica")
        print("üí° Digite 'quit' para sair")
        print()
        
        while True:
            try:
                user_input = input("RAG> ").strip()
                
                if not user_input:
                    continue
                
                # Processar comandos especiais
                command_result = self.process_command(user_input)
                
                if command_result == 'quit':
                    print("üëã Encerrando sistema RAG...")
                    if self.pipeline:
                        self.pipeline.save_history_to_file("rag_session_history.json")
                        print("üíæ Hist√≥rico salvo em rag_session_history.json")
                    print("üéØ Obrigado por usar o sistema RAG!")
                    break
                elif command_result:
                    continue  # Foi comando especial
                
                # Processar consulta normal
                self.process_query(user_input)
                
            except KeyboardInterrupt:
                print("\n\nüëã Encerrando sistema RAG...")
                break
            except Exception as e:
                print(f"‚ùå Erro: {e}")
                print("üí° Digite 'help' para ver comandos dispon√≠veis")


def main():
    """Fun√ß√£o principal."""
    demo = RAGInteractiveDemo()
    demo.run()


if __name__ == "__main__":
    main()